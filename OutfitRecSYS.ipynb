{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, Activation, Dot, Reshape,MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def process_image(path):\n",
    "    img = image.load_img(path, target_size=(224, 224, 3))\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/pracdat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(df):\n",
    "    \n",
    "    \n",
    "    data1, data2, labels = [], [], []\n",
    "\n",
    "    for _,row in df.iterrows():\n",
    "        img_one = process_image('data/'+ row['HeroID'])\n",
    "        img_two = process_image('data/'+ row['StylingID'])\n",
    "        label = row['Match']\n",
    "        labels.append(label)\n",
    "        \n",
    "#         combined_image = np.concatenate((img_one, img_two), axis =1)\n",
    "        data1.append(img_one)\n",
    "        data2.append(img_two)\n",
    "\n",
    "        \n",
    "    labels = np.array(labels)\n",
    "    data1 = np.array(data1)/255.0\n",
    "    data2 = np.array(data2)/255.0\n",
    "    \n",
    "#     print(len(data))\n",
    "#     print(len(labels))\n",
    "    return data1, data2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata1, traindata2, trainlabel = extract_data(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfit1 = Input(name = 'outfit1', shape = (224, 224, 3))\n",
    "outfit1Model = vision_model(outfit1)\n",
    "\n",
    "outfit2 = Input(name = 'outfit2', shape = (224, 224, 3))\n",
    "outfit2Model = vision_model(outfit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = Dot(name = 'dot_product', normalize = True, axes = 1)([outfit1Model, outfit2Model])\n",
    "merged = Reshape(target_shape = [1])(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Dense(1, activation = 'sigmoid')(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs =[outfit1, outfit2], outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "outfit1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "outfit2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 160000)       1735488     outfit1[0][0]                    \n",
      "                                                                 outfit2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1)            0           sequential_2[3][0]               \n",
      "                                                                 sequential_2[4][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           dot_product[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,735,490\n",
      "Trainable params: 1,735,490\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.8081 - accuracy: 0.5556\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.8076 - accuracy: 0.5556\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.7858 - accuracy: 0.5556\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.7323 - accuracy: 0.5556\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.7001 - accuracy: 0.5556\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.8210 - accuracy: 0.5556\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.8105 - accuracy: 0.5556\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.7882 - accuracy: 0.5556\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.7597 - accuracy: 0.5556\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.7208 - accuracy: 0.5556\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.7137 - accuracy: 0.5556\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.6762 - accuracy: 0.5556\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6505 - accuracy: 0.5556\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.7037 - accuracy: 0.5556\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6938 - accuracy: 0.5556\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.6485 - accuracy: 0.5556\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6342 - accuracy: 0.5556\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6625 - accuracy: 0.5556\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6417 - accuracy: 0.5556\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6317 - accuracy: 0.5556\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6259 - accuracy: 0.5556\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6288 - accuracy: 0.5556\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6207 - accuracy: 0.5556\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6229 - accuracy: 0.5556\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6130 - accuracy: 0.5556\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6098 - accuracy: 0.5556\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.5998 - accuracy: 0.5556\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6221 - accuracy: 0.5556\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6609 - accuracy: 0.5556\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.6314 - accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13ddf19b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([traindata1, traindata2], trainlabel,\n",
    "                    epochs=30,\n",
    "                    batch_size=9\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('first_attempt_class.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.read_csv('data/pracdatatest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata1, testdata2, testlabel = extract_data(predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.predict([testdata1, testdata2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7273589 ]\n",
      " [0.75668967]\n",
      " [0.74726164]\n",
      " [0.640111  ]]\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 3 nearest neighbors...\n",
      "[t-SNE] Indexed 4 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 4 samples in 0.004s...\n",
      "[t-SNE] Computed conditional probabilities for sample 4 / 4\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 36.584835\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.048696\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne_results = TSNE(n_components=2,verbose=1,metric='cosine').fit_transform(features)\n",
    "\n",
    "# Plot a scatter plot from the generated t-SNE results\n",
    "colormap = plt.cm.get_cmap('coolwarm')\n",
    "scatter_plot = plt.scatter(tsne_results[:,0],tsne_results[:,1],cmap=colormap)\n",
    "plt.colorbar(scatter_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-18965972e7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
