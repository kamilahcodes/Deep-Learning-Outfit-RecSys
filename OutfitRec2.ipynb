{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, input_shape =(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(path, model): \n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / norm(flattened_features)\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings(df):\n",
    "    \n",
    "    \n",
    "    data1, data2, labels = [], [], []\n",
    "    herocat, stylingcat = [],[]\n",
    "\n",
    "    for _,row in df.iterrows():\n",
    "        img_one = extract_features('data/'+ row['HeroID'], model)\n",
    "\n",
    "        img_two = extract_features('data/'+ row['StylingID'], model)\n",
    "\n",
    "        label = row['Match']\n",
    "        labels.append(label)\n",
    "        \n",
    "\n",
    "        data1.append(img_one)\n",
    "        data2.append(img_two)\n",
    "\n",
    "        \n",
    "    labels = np.array(labels)\n",
    "    data1 = np.array(data1)\n",
    "    data2 = np.array(data2)\n",
    "\n",
    "\n",
    "    return data1, data2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/pracdat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata1, traindata2, trainlabel = store_embeddings(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25088,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 25088)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dense, Activation, Dot, Reshape, concatenate, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kamilah/Desktop/FYP/src/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kamilah/Desktop/FYP/src/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kamilah/Desktop/FYP/src/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/kamilah/Desktop/FYP/src/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/kamilah/Desktop/FYP/src/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/30\n",
      "60/60 [==============================] - 2s 30ms/step - loss: 0.6931 - acc: 0.5333\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6884 - acc: 0.5500\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.6545 - acc: 0.5000\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5411 - acc: 0.5000\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.4304 - acc: 0.5000\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3661 - acc: 0.7500\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 1s 14ms/step - loss: 0.3467 - acc: 0.9500\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3440 - acc: 1.0000\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3428 - acc: 1.0000\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.3419 - acc: 1.0000\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3411 - acc: 1.0000\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3402 - acc: 1.0000\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3394 - acc: 1.0000\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3385 - acc: 1.0000\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3378 - acc: 1.0000\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 1s 12ms/step - loss: 0.3369 - acc: 1.0000\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3361 - acc: 1.0000\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3353 - acc: 1.0000\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3345 - acc: 1.0000\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.3337 - acc: 1.0000\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3329 - acc: 1.0000\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3321 - acc: 1.0000\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3314 - acc: 1.0000\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3306 - acc: 1.0000\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3298 - acc: 1.0000\n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.3291 - acc: 1.0000\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 1s 11ms/step - loss: 0.3283 - acc: 1.0000\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 1s 10ms/step - loss: 0.3276 - acc: 1.0000\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 1s 12ms/step - loss: 0.3268 - acc: 1.0000\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 0.3261 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x105a35f28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#img 1 pass through 2 relu layers\n",
    "outfit1_img = Input(name = 'outfit1img', shape = (25088,))\n",
    "\n",
    "    \n",
    "#img 2 pass through 2 relu layers\n",
    "outfit2_img = Input(name = 'outfit2img', shape = (25088,))\n",
    "\n",
    "#two Dense for item1\n",
    "outfit1imgdense = Dense(256, activation='relu')(outfit1_img)\n",
    "x1 = Dense(256, activation='relu')(outfit1imgdense)\n",
    "\n",
    "#two Dense for item2\n",
    "outfit2imgdense = Dense(256, activation='relu')(outfit2_img)\n",
    "x2 = Dense(256, activation='relu')(outfit2imgdense)\n",
    "\n",
    "# merge features using dot layer\n",
    "    \n",
    "merged = Dot(name = 'dot_product', normalize = False, axes = 1)([x1,x2]) \n",
    "#reshape for input into sigmoid\n",
    "merged = Reshape(target_shape = [1])(merged)\n",
    "out = Dense(1, activation = 'sigmoid')(merged)\n",
    "\n",
    "\n",
    "model1 = Model(inputs =[outfit1_img, outfit2_img], outputs = out)\n",
    "model1.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#commence training\n",
    "model1.fit([traindata1, traindata2], trainlabel, epochs=30, batch_size=20)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = pd.read_csv('data/pracdatatest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata1, testdata2, testlabel = store_embeddings(predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model1.predict([testdata1, testdata2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9481745]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47856745]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666852]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4790791]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('outfitrecsys1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model1, open('data/model1.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model \n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
